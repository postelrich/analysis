{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "data = pd.read_json('data/all_reviews.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e557470>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e563c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.groupby('author_name')['place_id'].count().sort_values(ascending=False).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text\n",
    "\n",
    "The text data isn't clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Always quiet. Always open. Usually pleasant staff. ',\n",
       "       'The food is decent and cheap but the employees are less than helpful.',\n",
       "       'Great place on Queens Boulevard for after-work get-togethers',\n",
       "       \"The owner's wife has been (and still is) a long-time client of my mom, and my mom frequents here for special occasions/family dinners. It was my first time going there and the owner + wife couldn't be nicer people to me, my mom + family. Phenomenal service, along with the food + quality. \\n\\n10/10 would dine here again.\",\n",
       "       \"Stellar / top notch Middle Eastern cuisine.   I believe the owner is Syrian because the flavorings and sauces have a Syrian spin to them.\\n\\nThe  Magic Combination for one is a stupendous value.   You'll be bursting at the seams for $17.  Honestly, I don't know how a human being can consume all that food.\\n\\nI saw people eating schwarma sandwiches which looked and smelled divine.\\n\\nHighly recommended.\"], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading spacy and its corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that lemmatize and removes stop words, punctuation, numbers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUMBERS = [str(n) for n in range(0, 10)]\n",
    "def clean(s):\n",
    "    clean_text = []\n",
    "    for w in nlp(s):\n",
    "        if not w.is_stop and not w.is_punct and not any(n in str(w) for n in NUMBERS):\n",
    "            clean_text.append(w.lemma_.lower())\n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function to the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['quiet open usually pleasant staff',\n",
       "       'food decent cheap employee helpful',\n",
       "       'great place queen boulevard work togethers',\n",
       "       \"owner 's wife long time client mom mom frequent special occasions/family dinner time go owner + wife not nice people mom + family phenomenal service food + quality \\n\\n dine\",\n",
       "       'stellar notch middle eastern cuisine    believe owner syrian flavoring sauce syrian spin \\n\\n   magic combination stupendous value    will burst seam $   honestly not know human consume food \\n\\n see people eat schwarma sandwich look smell divine \\n\\n highly recommend'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data.text.tolist()\n",
    "text = [t.lower() for t in text]\n",
    "clean_text = [clean(s) for s in text]\n",
    "data['text'] = clean_text\n",
    "data.text.values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling model\n",
    "\n",
    "Create a pipeline to vectorize the text data and run it through random forest classification. Use term frequency - inverse document frequency to conver the text to a function of its occurence in each review and occurence in all reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  TfidfVectorizer(max_df=0.5, ngram_range=(1,4), norm='l2', stop_words='english')),\n",
    "    ('classifier',  RandomForestClassifier(n_estimators=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11127 4770\n"
     ]
    }
   ],
   "source": [
    "rs = ShuffleSplit(n_splits=1, train_size=0.7, test_size=0.3, random_state=0)\n",
    "training_idx, testing_idx = next(rs.split(data))\n",
    "print(len(training_idx), len(testing_idx))\n",
    "training_data, testing_data = data.iloc[training_idx], data.iloc[testing_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf=Tr...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(training_data['text'].values, training_data.michelin_stars.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews classified: 11127\n",
      "Score: 0.974530276061\n",
      "Confusion matrix:\n",
      " [[4683    2    1    0]\n",
      " [  65    2    0    0]\n",
      " [  11    1    0    0]\n",
      " [   4    1    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rpostelnik/anaconda3/envs/analysis/lib/python3.5/site-packages/sklearn/metrics/classification.py:1023: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n",
      "/Users/rpostelnik/anaconda3/envs/analysis/lib/python3.5/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "predictions = pipeline.predict(testing_data.text.values)\n",
    "print('Total reviews classified:', len(training_data))\n",
    "print('Score:', f1_score(testing_data.michelin_stars, predictions, pos_label=0, average='weighted', labels=[0,1,2,3]))\n",
    "print('Confusion matrix:\\n', confusion_matrix(testing_data.michelin_stars, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_review = [clean(\"\"\"Food: The Chef's Special\n",
    "Attentive and friendly service.\n",
    "Prices were moderate.\n",
    "Medium rare was done correctly and the burger is not greasy. The fries were also a great addition.\n",
    "Atmosphere: sometimes there was an awkward calmness to it, but there would be remissions of small chit-chat\n",
    "Overall: would come back and highly recommend! Go Korzo! \"\"\")]\n",
    "pipeline.predict(good_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making an informative prediction\n",
    "\n",
    "Since so few restaurants get the Michelin distinction, we don't gain any use from restaurants that happened to not make the cut. It's also hard to make a clear definition for what is a 1, 2, or 3 star restaurant. To simplify the model, lets convert it 2 classes, a restaurant with or without michelin stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['michelin_rated'] = (data.michelin_stars > 0).astype(int)\n",
    "data.michelin_rated.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to run the random forest regressor so our model will score a restaurant review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11127 4770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 4), norm='l2', preprocessor=None, smooth_idf=Tr...imators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  TfidfVectorizer(max_df=0.5, ngram_range=(1,4), norm='l2', stop_words='english')),\n",
    "    ('classifier',  RandomForestClassifier(n_estimators=10))\n",
    "])\n",
    "rs = ShuffleSplit(n_splits=1, train_size=0.7, test_size=0.3, random_state=0)\n",
    "training_idx, testing_idx = next(rs.split(data))\n",
    "print(len(training_idx), len(testing_idx))\n",
    "training_data, testing_data = data.iloc[training_idx], data.iloc[testing_idx]\n",
    "pipeline.fit(training_data['text'].values, training_data.michelin_rated.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And checking the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews classified: 11127\n",
      "Score: 0.974713793393\n",
      "Confusion matrix:\n",
      " [[4682    4]\n",
      " [  81    3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rpostelnik/anaconda3/envs/analysis/lib/python3.5/site-packages/sklearn/metrics/classification.py:1023: UserWarning: Note that pos_label (set to 0) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  % (pos_label, average), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.predict(testing_data.text.values)\n",
    "print('Total reviews classified:', len(training_data))\n",
    "print('Score:', f1_score(testing_data.michelin_rated, predictions, pos_label=0, average='weighted', labels=[0,1]))\n",
    "print('Confusion matrix:\\n', confusion_matrix(testing_data.michelin_rated, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(good_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_fold = KFold(n=len(training_data), n_folds=6)\n",
    "scores = []\n",
    "confusion = None\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = training_data.iloc[train_indices]['text'].values\n",
    "    train_y = training_data.iloc[train_indices]['michelin_stars'].values\n",
    "\n",
    "    test_text = training_data.iloc[test_indices]['text'].values\n",
    "    test_y = training_data.iloc[test_indices]['michelin_stars'].values\n",
    "\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "\n",
    "    if isinstance(confusion, pd.DataFrame):\n",
    "        confusion += confusion_matrix(test_y, predictions)\n",
    "    else:\n",
    "        confusion = confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, pos_label=0, average='weighted', labels=[0,1,2,3])\n",
    "    scores.append(score)\n",
    "\n",
    "print('Total reviews classified:', len(training_data))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examples = [\"Really good meal, pricey and ~3 hours long. All the uni dishes were excellent. The appetizer / pre-sushi courses were better than the sushi courses. While I enjoyed them I was expecting a little more out of the sushi.\"]\n",
    "# example_counts = pipeline.transform(examples)\n",
    "predictions = pipeline.predict(testing_data.text)\n",
    "predictions # [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline.predict(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline.get_params()['vectorizer'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(data.michelin_stars > 0) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.groupby('michelin_stars')['index'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
